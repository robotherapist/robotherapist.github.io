---
layout: post
---

## What is fairness?

Fairness, in this context, is trying to correct biases in machine learning models. Decisions made by an ML model may be called "unfair" if they're based on variables we consider "sensitive" such as gender, ethnicity, sexual orientation, or disability. Of course in some algorithms these variables might want to be considered while in others they might want to be ignored. It doesn't help that humans haven't created some perfect ethical code so fairness is subjective. But what we know we want to do is reduce harm to a group of people by mistake. And this is already a problem! COMPAS for example, a decision support tool used in the US judicial system, had its [accuracy disputed in 2016](https://en.wikipedia.org/wiki/COMPAS_(software)). 

## Fairness Metrics

Academia and industry have started trying to quantify fairness and unfairness so that we can automatically identify poorly performing algorithms. While these techniques haven't really been rolled out much, for example Facebook has faced criticism for not requiring their internal tool Fairlearn to be used, I think if we start writing about it within industry outside of big tech we may be able to move best practices forward. 

### Demographic parity

### Equalized odds

### Equal opportunity

